<!DOCTYPE html>
<html>
  <head></head>

  <body>
    <p>
      When using auto model selection, VS Code uses a variable model multiplier
      based on the automatically selected model. If you are a paid user, auto
      applies a 10% request discount. For example, if auto selects Sonnet 4, it
      will be counted as 0.9x of a premium request; if auto selects GPT-5-mini,
      this counts as 0x because the model is included for paid users. You can
      see which model and model multiplier are used by hovering over the chat
      response.
    </p>

    <p>
      When using auto model selection, VS Code uses a variable model multiplier
      based on the automatically selected model. If you are a paid user, auto
      applies a 10% request discount. For example, if auto selects Sonnet 4, it
      will be counted as 0.9x of a premium request; if auto selects GPT-5-mini,
      this counts as 0x because the model is included for paid users. You can
      see which model and model multiplier are used by hovering over the chat
      response.When using auto model selection, VS Code uses a variable model
      multiplier based on the automatically selected model. If you are a paid
      user, auto applies a 10% request discount. For example, if auto selects
      Sonnet 4, it will be counted as 0.9x of a premium request; if auto selects
      GPT-5-mini, this counts as 0x because the model is included for paid
      users. You can see which model and model multiplier are used by hovering
      over the chat response.
    </p>

    <p>
      Faster responses, a lower chance of rate limiting, and 10% off premium
      requests for paid users - auto picks the best available model for each
      request based on current capacity and performance. With auto you can’t
      choose a specific model, auto handles that for you. Auto model selection
      in Chat is being rolled out in preview to all GitHub Copilot users in VS
      Code, starting with the individual plans.Faster responses, a lower chance
      of rate limiting, and 10% off premium requests for paid users - auto picks
      the best available model for each request based on current capacity and
      performance. With auto you can’t choose a specific model, auto handles
      that for you. Auto model selection in Chat is being rolled out in preview
      to all GitHub Copilot users in VS Code, starting with the individual
      plans.Faster responses, a lower chance of rate limiting, and 10% off
      premium requests for paid users - auto picks the best available model for
      each request based on current capacity and performance. With auto you
      can’t choose a specific model, auto handles that for you. Auto model
      selection in Chat is being rolled out in preview to all GitHub Copilot
      users in VS Code, starting with the individual plans.
    </p>
  </body>
</html>
